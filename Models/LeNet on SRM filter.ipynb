{"cells":[{"cell_type":"markdown","metadata":{"id":"oWaqOI38dGH9"},"source":["# LeNet on SRM Filter"]},{"cell_type":"markdown","metadata":{},"source":["Since the SRM Filter produces 1-channel grayscale images, we can't use the pretrained ImageNet weights off EfficientNet which expects 3 channel RGB images. For this reason, we'll use LeNet since it still got a very high accuracy without any pretraining"]},{"cell_type":"markdown","metadata":{"id":"8dFgUScndalT"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XKBKHOsrv4BX"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n"]},{"cell_type":"markdown","metadata":{"id":"Hb5Pd_ezdenZ"},"source":["## Load the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0nIVCycwObR"},"outputs":[],"source":["train_data = np.load('Noise_Train.npz')\n","test_data = np.load('Noise_Test.npz')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTcbnUsgwOYw"},"outputs":[],"source":["X_train = train_data['images']\n","y_train = train_data['labels']\n","\n","X_test = test_data['images']\n","y_test = test_data['labels']\n","\n","label_names = train_data['label_names']\n"]},{"cell_type":"markdown","metadata":{"id":"rJcwHnbSdhEC"},"source":["## Standardize the pixel data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1699669729484,"user":{"displayName":"Riya Bharamaraddi","userId":"03968761791875395690"},"user_tz":300},"id":"IpLwgFgLySVS","outputId":"7df4f992-8bee-45f3-9268-fcb3b72aaa69"},"outputs":[{"data":{"text/plain":["(100000, 32, 32, 1)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["m_train = X_train.shape[0]\n","X_train = X_train.reshape(m_train, 32, 32, 1)\n","\n","m_test = X_test.shape[0]\n","X_test = X_test.reshape(m_test, 32, 32, 1)\n","\n","X_train.shape\n"]},{"cell_type":"markdown","metadata":{"id":"jr_OvfgtdmG7"},"source":["## Building LeNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpN_EvNBwUaG"},"outputs":[],"source":["def build_LeNet(input_shape=(32, 32, 1), outputs=2):\n","    X0 = Input(shape=input_shape)\n","    X1 = Conv2D(20, kernel_size=(5, 5), padding='same', input_shape=input_shape, activation='relu')(X0)\n","    X1_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X1)\n","    X2 = Conv2D(50, kernel_size=(5, 5), padding='same', activation='relu')(X1_pool)\n","    X2_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X2)\n","    X2_flat = Flatten()(X2_pool)\n","    X3 = Dense(500, activation='relu')(X2_flat)\n","    Ph = Dense(outputs, activation='softmax')(X3)\n","    return Model(inputs=[X0], outputs=[Ph])\n","    # return Model(inputs=[X0], outputs=[X1, X1_pool, X2, X2_pool, X2_flat, X3, Ph])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626,"status":"ok","timestamp":1699669731108,"user":{"displayName":"Riya Bharamaraddi","userId":"03968761791875395690"},"user_tz":300},"id":"2BoQ0tR_wOf4","outputId":"f84d06bb-b4b4-422a-e870-b59b9b95d677"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 32, 32, 20)        520       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 16, 16, 20)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 16, 16, 50)        25050     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 8, 8, 50)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 3200)              0         \n","                                                                 \n"," dense (Dense)               (None, 500)               1600500   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 1002      \n","                                                                 \n","=================================================================\n","Total params: 1627072 (6.21 MB)\n","Trainable params: 1627072 (6.21 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["LeNet = build_LeNet()\n","LeNet.summary()\n"]},{"cell_type":"markdown","metadata":{"id":"v0nB51Xmdq7Z"},"source":["We'll define some hyperparameters for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_SIu4QNy2HU"},"outputs":[],"source":["# callbacks\n","checkpt = ModelCheckpoint('LeNet_Noise_Filter.h5', save_best_only=True, verbose=0)\n","tb = TensorBoard(log_dir='tb_logs')\n","e_stop = EarlyStopping(patience=3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCh691PA02zU"},"outputs":[],"source":["batch_size = 100\n","epochs = 10\n","learning_rate = 2e-4\n","optimizer = Adam(learning_rate=learning_rate)\n","loss = 'sparse_categorical_crossentropy'\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJ354zzPyufq"},"outputs":[],"source":["LeNet.compile(loss=loss, optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55217,"status":"ok","timestamp":1699669786323,"user":{"displayName":"Riya Bharamaraddi","userId":"03968761791875395690"},"user_tz":300},"id":"um8jcNP1y79H","outputId":"d14ad260-b92c-40ed-8f4b-0b86ee5781a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","800/800 [==============================] - 16s 7ms/step - loss: 0.8723 - accuracy: 0.7403 - val_loss: 0.4408 - val_accuracy: 0.7915\n","Epoch 2/10\n"," 22/800 [..............................] - ETA: 3s - loss: 0.4237 - accuracy: 0.8041"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["800/800 [==============================] - 4s 5ms/step - loss: 0.4220 - accuracy: 0.8063 - val_loss: 0.4037 - val_accuracy: 0.8159\n","Epoch 3/10\n","800/800 [==============================] - 5s 6ms/step - loss: 0.3818 - accuracy: 0.8288 - val_loss: 0.3839 - val_accuracy: 0.8313\n","Epoch 4/10\n","800/800 [==============================] - 5s 6ms/step - loss: 0.3410 - accuracy: 0.8495 - val_loss: 0.3602 - val_accuracy: 0.8429\n","Epoch 5/10\n","800/800 [==============================] - 4s 6ms/step - loss: 0.3120 - accuracy: 0.8651 - val_loss: 0.3747 - val_accuracy: 0.8343\n","Epoch 6/10\n","800/800 [==============================] - 4s 5ms/step - loss: 0.2808 - accuracy: 0.8810 - val_loss: 0.3369 - val_accuracy: 0.8564\n","Epoch 7/10\n","800/800 [==============================] - 6s 7ms/step - loss: 0.2491 - accuracy: 0.8955 - val_loss: 0.3467 - val_accuracy: 0.8540\n","Epoch 8/10\n","800/800 [==============================] - 5s 6ms/step - loss: 0.2205 - accuracy: 0.9081 - val_loss: 0.3447 - val_accuracy: 0.8601\n","Epoch 9/10\n","800/800 [==============================] - 4s 5ms/step - loss: 0.1814 - accuracy: 0.9263 - val_loss: 0.3701 - val_accuracy: 0.8589\n"]}],"source":["lenet_hist = LeNet.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=[checkpt, tb, e_stop])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47970,"status":"ok","timestamp":1699669939163,"user":{"displayName":"Riya Bharamaraddi","userId":"03968761791875395690"},"user_tz":300},"id":"OX0HlYgFLmiO","outputId":"05e53d1b-382b-4489-c913-d0d8d8d660ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["625/625 [==============================] - 3s 4ms/step - loss: 0.3822 - accuracy: 0.8547\n"]}],"source":["test_loss, test_accuracy = LeNet.evaluate(X_test, y_test)\n"]},{"cell_type":"markdown","metadata":{},"source":["Considering we went from RGB images to grayscale images with just the noise of the original images, it's surprising that we were able to get a full 85% accuracy. This might suggest that the noise is very important in classifying the images, which is a bit surprising since EfficientNet barely dropped in performance on the Median Blur and the Gaussian Blur which are supposed to remove the noise. More work should be done to investigate this"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
